{"cells":[{"cell_type":"markdown","metadata":{"id":"qmSws8EXnT0j"},"source":["# Solving the 1D fluid flow problem using PINNs (Physics Informed Neural Networks)\n","\n","## Problem Statement \n","\n","let us have the following problem \n","\n","$$\n","\\frac{\\partial}{\\partial x}\\left(\\frac{\\beta_c k A}{\\mu B} \\frac{\\partial p}{\\partial x}\\right) \\Delta x+q_{s c}=\\frac{V_b \\phi c_t}{\\alpha_c B} \\frac{\\partial p}{\\partial t}\n","$$\n","\n","Assume that the viscosity and formation volume factor are constant and using the following data: Length $=2500 \\mathrm{ft}$, Width $=80 \\mathrm{ft}$, thickness $=60 \\mathrm{ft} \\quad B=1.2 \\mathrm{bbl} / \\mathrm{stb}, \\alpha_c=5.615, \\beta_c=1.127 \\times 10^{-3}$ Well radius $r_w=0.33 \\mathrm{ft}, \\quad$ Viscosity $\\mu=1.3 \\mathrm{cpt}=1.3 \\mathrm{cp}$\n","\n","Total compressibility $c_t=7.3 \\times 10^{-6} \\mathrm{psi}^{-1} \\quad$ Initial pressure $p_i=5000 \\mathrm{psi}$ in all grid blocks Constant injection rate $700 \\mathrm{stb} /$ day from Grid \\# 2 . Constant production rate of $900 \\mathrm{stb} /$ day at Grid \\# 4 . There is a leakage of 250bbl/day of fluid at the left boundary $(x=0)$ and the pressure is held constant at the right boundary $(x=L)$ at 5200 psi and time-step size is 0.2 day. The table below gives the properties of each grid block:"]},{"cell_type":"markdown","metadata":{},"source":["### Setting the variables and constants\n","\n","Let us have \n","$$ \\lambda = \\dfrac{\\beta_c A}{\\mu B} \\quad \\& \\quad \\gamma = \\dfrac{V_b c_t}{\\alpha_c B}$$\n","So out problem can be written as \n"," $$\n","\\frac{\\partial}{\\partial x} \\left(\\lambda k \\frac{\\partial p}{\\partial x}\\right) \\Delta x+q_{s c}=\\gamma \\phi \\frac{\\partial p}{\\partial t}\n","$$\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from matplotlib import pyplot as plt"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"data":{"text/plain":["'cpu'"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# set the device to be a GPU, if it is there\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"]},{"cell_type":"markdown","metadata":{},"source":["### Setting the NEural network "]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# the model\n","class FCN(nn.Module):\n","    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n","        super().__init__()\n","        activation = nn.Tanh\n","        self.fcs = nn.Sequential(*[\n","            nn.Linear(N_INPUT, N_HIDDEN),\n","            activation()\n","\n","        ])\n","\n","\n","        self.fch =nn.Sequential(*[ nn.Sequential(*[\n","            nn.Linear(N_HIDDEN, N_HIDDEN),\n","            activation()\n","\n","        ]) for _ in range(N_LAYERS-1)])\n","        self.fce = nn.Linear(N_HIDDEN,N_OUTPUT)\n","        def weights_initialization(self):\n","                \"\"\"\"\n","                When we define all the modules such as the layers in '__init__()'\n","                method above, these are all stored in 'self.modules()'.\n","                We go through each module one by one. This is the entire network,\n","                basically.\n","                \"\"\"\n","        for m in self.modules():\n","            if isinstance(m, nn.Linear):\n","                nn.init.xavier_normal_(m.weight,gain=1.0)\n","                nn.init.constant_(m.bias, 0)\n","    def forward(self, x,t):\n","        inputs = torch.cat([x,t],axis=1) # combined two arrays of 1 columns each to one array of 2 columns\n","        inputs = self.fcs(inputs)\n","        inputs = self.fch(inputs)\n","        inputs = self.fce(inputs)\n","        return inputs"]},{"cell_type":"markdown","metadata":{},"source":["Setting the PDE loss"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["x_0 = 0.0\n","x_f = 10000.0\n","h =  100.0\n","\n","t_0 = 0.0\n","t_f = 50.0 \n","k = 0.2 \n","\n","def generate_data(x_num = int((x_f - x_0)/h), t_num=int((t_f-t_0)/k)):\n","    x_axis = torch.linspace(x_0, x_f,  x_num + 2)[1:-1] #exclude the boundary\n","    t_axis = torch.linspace(t_0, t_f, t_num +1)[1:]\n","    data = torch.cartesian_prod(x_axis, t_axis)\n","    return torch.split(data, 1, 1)"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["# Input points from the interior of the domain\n","x_physics , t_physics = generate_data()\n","x_physics = x_physics.requires_grad_().to(device)\n","t_physics = t_physics.requires_grad_().to(device)\n","examples_num = len(x_physics)\n","\n","n_of_points_per_grid = examples_num / 100"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["x_left = torch.tensor( [x_0]*examples_num ).unsqueeze(-1).requires_grad_().to(device)\n","x_right = torch.tensor( [x_f]*examples_num ).unsqueeze(-1).requires_grad_().to(device)\n","# Use NumPy to load data from the text file\n","numpy_perm = np.loadtxt('perm.csv').repeat(n_of_points_per_grid).reshape(-1,1)\n","numpy_porosity = np.loadtxt('porosity.csv').repeat(n_of_points_per_grid).reshape(-1,1)\n","# Convert NumPy array to PyTorch tensor\n","perm = torch.tensor(numpy_perm).requires_grad_()\n","porosity = torch.tensor(numpy_porosity)\n","# Now you can use tensor_data in your PyTorch code\n","\n","t_init = torch.tensor([t_0] *examples_num ).unsqueeze(-1).requires_grad_().to(device)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["pinn = FCN(2,1,32,3)\n","mse_cost_function = torch.nn.MSELoss()\n","optimizer = optim.Adam(pinn.parameters(), lr=1e-4)\n","scheduler = optim.lr_scheduler.ExponentialLR(optimizer, 0.45)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def pde():\n","    "]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"ename":"RuntimeError","evalue":"One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[1;32mIn[47], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m p \u001b[38;5;241m=\u001b[39m pinn(x_physics,t_physics)\n\u001b[0;32m     11\u001b[0m p_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(p,x_physics,torch\u001b[38;5;241m.\u001b[39mones_like(p), create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 12\u001b[0m p_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(p,t_init,torch\u001b[38;5;241m.\u001b[39mones_like(p), create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     13\u001b[0m ps_xx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mgrad(p_x \u001b[38;5;241m*\u001b[39m perm, x_physics, torch\u001b[38;5;241m.\u001b[39mones_like(p_x), create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     14\u001b[0m pde_loss \u001b[38;5;241m=\u001b[39m ps_xx \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m-\u001b[39m porosity \u001b[38;5;241m*\u001b[39m p_t \n","File \u001b[1;32md:\\anaconda\\envs\\MX_project\\Lib\\site-packages\\torch\\autograd\\__init__.py:303\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    304\u001b[0m         t_outputs, grad_outputs_, retain_graph, create_graph, t_inputs,\n\u001b[0;32m    305\u001b[0m         allow_unused, accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","\u001b[1;31mRuntimeError\u001b[0m: One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior."]}],"source":["total_losses = []\n","iteration = []\n","boundary_loss = []\n","epochs = 2\n","\n","for epoch in range(1, epochs+1):\n","    optimizer.zero_grad()\n","\n","    #initial loss\n","    p = pinn(x_physics,t_init)\n","    p_x = torch.autograd.grad(p,x_physics,torch.ones_like(p), create_graph=True)[0]\n","    p_t = torch.autograd.grad(p,t_init,torch.ones_like(p), create_graph=True)[0]\n","    ps_xx = torch.autograd.grad(p_x * perm, x_physics, torch.ones_like(p_x), create_graph=True)[0]\n","    pde_loss = ps_xx * 100 - porosity * p_t \n","    mse_cost_function(pde_loss, torch.zeros_like(pde_loss))\n","\n","    # Boundary loss \n","    p = pinn(x_left,t_physics)"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([25000, 1])"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["p.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNhctF8qPLekb0VXXb+tyBN","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
