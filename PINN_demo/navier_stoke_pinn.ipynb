{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt for solving navier-stoke equation using PINNS\n",
    "\n",
    "let us take the following PDE \n",
    "$$\n",
    "   \n",
    "    \\frac{\\partial u}{\\partial t} \n",
    "    + u \\frac{\\partial u}{\\partial x} + v \\frac{\\partial u}{\\partial y}\n",
    "    = \n",
    "    -\\frac{1}{\\rho} \\frac{\\partial p}{\\partial x} \n",
    "    + \\nu \\left( \n",
    "    \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2}\n",
    "    \\right) \\\\[10pt]\n",
    "\n",
    "  \n",
    "    \\frac{\\partial v}{\\partial t} \n",
    "    + u \\frac{\\partial v}{\\partial x} + v \\frac{\\partial v}{\\partial y}\n",
    "    = \n",
    "    -\\frac{1}{\\rho} \\frac{\\partial p}{\\partial y} \n",
    "    + \\nu \\left( \n",
    "    \\frac{\\partial^2 v}{\\partial x^2} + \\frac{\\partial^2 v}{\\partial y^2}\n",
    "    \\right)\n",
    "    \\\\[10pt]\n",
    "   \n",
    "    \\left( \\frac{\\partial u}{\\partial x} \\right)^2 +\n",
    "    2 \\left( \\frac{\\partial u}{\\partial y} \\right)\n",
    "    \\left( \\frac{\\partial v}{\\partial y} \\right) +\n",
    "    \\left( \\frac{\\partial v}{\\partial y} \\right)^2\n",
    "    = -\\frac{1}{\\rho} \n",
    "    \\left(\n",
    "    \\frac{\\partial^2 p}{\\partial x^2} \n",
    "    + \\frac{\\partial^2 p}{\\partial y^2}\n",
    "    \\right)\n",
    "    \n",
    "$$\n",
    "\n",
    "\n",
    "The boundary conditions for the velocity are the following.\n",
    "$$\n",
    "u(t, x, l_y) = 1, \\quad u(t, x, 0) = 0, \\quad\n",
    "u(t, 0, y) = 0, \\quad u(t, l_x, y) = 0\n",
    "$$\n",
    "$$\n",
    "v(t, x, l_y) = 0, \\quad v(t, x, 0) = 0, \\quad\n",
    "v(t, 0, y) = 0, \\quad v(t, l_x, y) = 0\n",
    "$$\n",
    "\n",
    "consider $l_x = l_y = 1$\n",
    "\n",
    "The boundary condition for the pressure\n",
    "$$\n",
    "\\frac{\\partial p}{\\partial x}\\Big|_{x=0} = 0, \\quad \n",
    "\\frac{\\partial p}{\\partial x}\\Big|_{x=l_x} = 0, \\quad \n",
    "\\frac{\\partial p}{\\partial y}\\Big|_{y=0} = 0, \\quad \n",
    "p(t, x, l_y) = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PINNs attempt\n",
    "\n",
    "We are going to train a neural network on the boundary conditions and the pde as constraints to find $u, v \\& p$ \n",
    "\n",
    "The neural networkd is going to take 3 inputs (time, x, y) and produces 3 output (u, v, p), thus we need to initialize the inputs with the right dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to have $t \\in [0,0.1]$ since we only want to see how system evolves in a small time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputs(train=10, test=50):\n",
    "    x_train = torch.linspace(0, 1, train, requires_grad=True).reshape(-1, 1, 1)\n",
    "    y_train = torch.linspace(0, 1, train, requires_grad= True).reshape(1, -1, 1)\n",
    "    t_train = torch.linspace(0, 0.1, train, requires_grad=True).reshape(1, 1, -1)\n",
    "\n",
    "    x_test = torch.linspace(0, 1, test, requires_grad=True).reshape(-1, 1, 1)\n",
    "    y_test = torch.linspace(0, 1, test, requires_grad=True).reshape(1, -1, 1)\n",
    "    t_test = torch.linspace(0, 0.1, test, requires_grad=True).reshape(1, 1, -1)\n",
    "\n",
    "    # Use torch.meshgrid to create 3D grids for training and testing\n",
    "    x_grid_train, y_grid_train, t_grid_train = torch.meshgrid(x_train.squeeze(), y_train.squeeze(), t_train.squeeze())\n",
    "    x_grid_test, y_grid_test, t_grid_test = torch.meshgrid(x_test.squeeze(), y_test.squeeze(), t_test.squeeze())\n",
    "\n",
    "    # Reshape the grids to be consistent with the original code\n",
    "\n",
    "\n",
    "    train_dict = {\n",
    "        'x': x_grid_train,\n",
    "        'y': y_grid_train,\n",
    "        't': t_grid_train\n",
    "    }\n",
    "\n",
    "    test_dict = {\n",
    "        'x': x_grid_test,\n",
    "        'y': y_grid_test,\n",
    "        't': t_grid_test\n",
    "    }\n",
    "\n",
    "    return train_dict, test_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model\n",
    "class FCN(nn.Module):\n",
    "    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN, N_LAYERS):\n",
    "        super().__init__()\n",
    "        activation = nn.Tanh\n",
    "        self.fcs = nn.Sequential(*[\n",
    "            nn.Linear(N_INPUT, N_HIDDEN),\n",
    "            activation()\n",
    "\n",
    "        ])\n",
    "\n",
    "\n",
    "        self.fch =nn.Sequential(*[ nn.Sequential(*[\n",
    "            nn.Linear(N_HIDDEN, N_HIDDEN),\n",
    "            activation()\n",
    "\n",
    "        ]) for _ in range(N_LAYERS-1)])\n",
    "        self.fce = nn.Linear(N_HIDDEN,N_OUTPUT)\n",
    "        def weights_initialization(self):\n",
    "                \"\"\"\"\n",
    "                When we define all the modules such as the layers in '__init__()'\n",
    "                method above, these are all stored in 'self.modules()'.\n",
    "                We go through each module one by one. This is the entire network,\n",
    "                basically.\n",
    "                \"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight,gain=1.0)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    def forward(self, x, y, t):\n",
    "        inputs = torch.cat((x, y, t), 1)\n",
    "        inputs = self.fcs(inputs)\n",
    "        inputs = self.fch(inputs)\n",
    "        output = self.fce(inputs)\n",
    "        \n",
    "        # Split the output into u, v, and p\n",
    "        u, v, p = torch.split(output, 1, dim=1)\n",
    "        \n",
    "\n",
    "        return u, v, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_loss(x,y,t,net,rho=1, train = 10):\n",
    "    u, v, p = net(x,y,t) \n",
    "    u_x = torch.autograd.grad(u, x,torch.ones_like(u), create_graph=True)[0]\n",
    "    u_xx = torch.autograd.grad(u_x, x, torch.ones_like(u_x),create_graph=True)[0]\n",
    "    u_y = torch.autograd.grad(u, y,torch.ones_like(u), create_graph=True)[0]\n",
    "    u_yy = torch.autograd.grad(u_y, y,torch.ones_like(u_y), create_graph=True)[0]\n",
    "    u_t = torch.autograd.grad(u, t, torch.ones_like(u), create_graph=True)[0]\n",
    "\n",
    "    v_x = torch.autograd.grad(v, x,torch.ones_like(v), create_graph=True)[0]\n",
    "    v_xx = torch.autograd.grad(v_x, x, torch.ones_like(v_x),create_graph=True)[0]\n",
    "    v_y = torch.autograd.grad(v, y,torch.ones_like(v), create_graph=True)[0]\n",
    "    v_yy = torch.autograd.grad(v_y, y,torch.ones_like(v_y), create_graph=True)[0]\n",
    "    v_t = torch.autograd.grad(v,t,torch.ones_like(v_y), create_graph=True)[0]\n",
    "\n",
    "    p_x = torch.autograd.grad(p,x,torch.ones_like(p), create_graph=True)[0]\n",
    "    p_xx = torch.autograd.grad(p_x,x,torch.ones_like(p_x), create_graph=True)[0]\n",
    "    p_y = torch.autograd.grad(p,y,torch.ones_like(p), create_graph=True)[0]\n",
    "    p_yy = torch.autograd.grad(p_y,y,torch.ones_like(p_y), create_graph=True)[0]\n",
    "\n",
    "\n",
    "    # Compute PDE losses\n",
    "    loss1 = u_t + u * u_x + v * u_y + (1/rho) * p_x - v * (u_xx + u_yy)\n",
    "    loss2 = v_t + u * v_x + v * v_y + (1/rho) * p_y - v * (v_xx + v_yy)\n",
    "    loss3 = (u_x)**2 + 2 * u_y * v_y + (v_y)**2 + (1/rho) * (p_xx + p_yy)\n",
    "\n",
    "    # Store losses in a dictionary\n",
    "    losses = {\n",
    "        'PDE1': loss1,\n",
    "        'PDE2': loss2,\n",
    "        'PDE3': loss3\n",
    "    }\n",
    "    loss_added = loss1+loss2+loss3\n",
    "\n",
    "\n",
    "    return losses, loss_added\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting the boundary conditions \n",
    "We are going to set the boundary conditions for neuman and dirchlit as the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boundaries_dict(train = 10, test = 50):\n",
    "    y_up = torch.ones((train**3,1),requires_grad=True)\n",
    "    y_down = torch.zeros((train**3,1),requires_grad=True)\n",
    "    x_right = torch.ones((train**3,1),requires_grad=True)\n",
    "    x_left = torch.zeros((train**3,1),requires_grad=True)\n",
    "\n",
    "    boundaries = {\n",
    "        'y_up': y_up,\n",
    "        'y_down': y_down,\n",
    "        'x_left': x_left,\n",
    "        'x_right': x_right\n",
    "    }\n",
    "\n",
    "    return boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building the NN\n",
    "\n",
    "We are going to build NN with 3 inputs and 3 outpus as we mentioned before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinn = FCN(3,3,64,4)\n",
    "mse_cost_function = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(pinn.parameters(), lr=1e-3)\n",
    "MSE_loss = []\n",
    "iteration = []\n",
    "boundary_loss = []\n",
    "train_dict, test_dict = inputs()\n",
    "boundaries = boundaries_dict()\n",
    "\n",
    "def iterations(train=10, test = 50):\n",
    "\n",
    "    \n",
    "    for i in range(5001):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #Boundary loss, 1- top \"y=1\"\n",
    "\n",
    "        u, v , p = pinn(train_dict['x'].reshape(-1,1),boundaries['y_up'].reshape(-1,1),\n",
    "                         train_dict['t'].reshape(-1,1))\n",
    "        loss1 = mse_cost_function(u, torch.ones((train**3,1)))\n",
    "        loss2 = mse_cost_function(v, torch.zeros((train**3,1)))\n",
    "        loss3 = mse_cost_function(p, torch.zeros((train**3,1)))\n",
    "\n",
    "        #Boundary loss, 2 - down \"y=0\"\n",
    "        u, v , p = pinn(train_dict['x'].reshape(-1,1),boundaries['y_down'].reshape(-1,1),\n",
    "                         train_dict['t'].reshape(-1,1))\n",
    "        loss4 = mse_cost_function(u, torch.zeros((train**3,1)))\n",
    "        loss5 = mse_cost_function(v, torch.zeros((train**3,1)))\n",
    "        p_y = torch.autograd.grad(p,boundaries['y_down'].reshape(-1,1), torch.ones_like(p), create_graph=True)[0]\n",
    "        loss6 = mse_cost_function(p_y, torch.zeros((train**3,1)))      \n",
    "\n",
    "        # Boundary loss, 3 - left \"x=0\" \n",
    "        u, v , p = pinn(boundaries['x_left'].reshape(-1,1),train_dict['y'].reshape(-1,1),\n",
    "                         train_dict['t'].reshape(-1,1))\n",
    "        loss7 = mse_cost_function(u, torch.zeros((train**3,1)))\n",
    "        loss8 = mse_cost_function(v, torch.zeros((train**3,1)))\n",
    "        p_x = torch.autograd.grad(p,boundaries['x_left'].reshape(-1,1), torch.ones_like(p), create_graph=True)[0]\n",
    "        loss9 = mse_cost_function(p_x, torch.zeros((train**3,1))) \n",
    "\n",
    "\n",
    "        # Boundary loss, 4 - right \"x=1\" \n",
    "        u, v , p = pinn(boundaries['x_right'].reshape(-1,1),train_dict['y'].reshape(-1,1),\n",
    "                         train_dict['t'].reshape(-1,1))\n",
    "        loss10 = mse_cost_function(u, torch.zeros((train**3,1)))\n",
    "        loss11 = mse_cost_function(v, torch.zeros((train**3,1)))\n",
    "        p_x = torch.autograd.grad(p,boundaries['x_right'].reshape(-1,1), torch.ones_like(p), create_graph=True)[0]\n",
    "        loss12 = mse_cost_function(p_x, torch.zeros((train**3,1))) \n",
    "\n",
    "        # pde loss\n",
    "\n",
    "        pde_losses, losses_added = pde_loss(x = train_dict['x'], y = train_dict['y'], t = train_dict['t'], net = pinn  )\n",
    "        loss13 = mse_cost_function(losses_added, torch.zeros((train**3,1)))\n",
    "        loss = loss1+loss2+loss3+loss4+loss5+loss6+loss7+loss8+loss9+loss10+loss11+loss12+loss13\n",
    "\n",
    "        # back propagation\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\Documents\\MX_PROGRAM\\project\\MX-Project\\PINN_demo\\navier_stoke_pinn.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Documents/MX_PROGRAM/project/MX-Project/PINN_demo/navier_stoke_pinn.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m iterations()\n",
      "\u001b[1;32md:\\Documents\\MX_PROGRAM\\project\\MX-Project\\PINN_demo\\navier_stoke_pinn.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/MX_PROGRAM/project/MX-Project/PINN_demo/navier_stoke_pinn.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m loss4 \u001b[39m=\u001b[39m mse_cost_function(u, torch\u001b[39m.\u001b[39mzeros((train\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m3\u001b[39m,\u001b[39m1\u001b[39m)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/MX_PROGRAM/project/MX-Project/PINN_demo/navier_stoke_pinn.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m loss5 \u001b[39m=\u001b[39m mse_cost_function(v, torch\u001b[39m.\u001b[39mzeros((train\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m3\u001b[39m,\u001b[39m1\u001b[39m)))\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Documents/MX_PROGRAM/project/MX-Project/PINN_demo/navier_stoke_pinn.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m p_y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgrad(p,boundaries[\u001b[39m'\u001b[39m\u001b[39my_down\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m), torch\u001b[39m.\u001b[39mones_like(p), create_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/MX_PROGRAM/project/MX-Project/PINN_demo/navier_stoke_pinn.ipynb#X11sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m loss6 \u001b[39m=\u001b[39m mse_cost_function(p_y, torch\u001b[39m.\u001b[39mzeros((train\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m3\u001b[39m,\u001b[39m1\u001b[39m)))      \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Documents/MX_PROGRAM/project/MX-Project/PINN_demo/navier_stoke_pinn.ipynb#X11sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Boundary loss, 3 - left \"x=0\" \u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\MX_project\\Lib\\site-packages\\torch\\autograd\\__init__.py:303\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[39mreturn\u001b[39;00m _vmap_internals\u001b[39m.\u001b[39m_vmap(vjp, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, allow_none_pass_through\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[0;32m    302\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 303\u001b[0m     \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39m_execution_engine\u001b[39m.\u001b[39mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    304\u001b[0m         t_outputs, grad_outputs_, retain_graph, create_graph, t_inputs,\n\u001b[0;32m    305\u001b[0m         allow_unused, accumulate_grad\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: One of the differentiated Tensors appears to not have been used in the graph. Set allow_unused=True if this is the desired behavior."
     ]
    }
   ],
   "source": [
    "iterations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MX_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
